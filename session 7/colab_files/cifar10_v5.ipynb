{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imb7syhCpIZM",
        "outputId": "c1ac6de1-105e-4c2a-ef8d-ef2a5bbd332a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# import torchvision.transforms as transforms\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# ðŸ“˜ Albumentations Augmentation Guide\n",
        "\n",
        "Albumentations is a **fast and flexible image augmentation library** for computer vision. It is widely used with **PyTorch, TensorFlow, and Keras** for improving generalization of models.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ Why use augmentations?\n",
        "\n",
        "* Prevent **overfitting** by exposing the model to varied data.\n",
        "* Improve **robustness** to transformations like flips, rotations, noise, or occlusions.\n",
        "* Simulate real-world conditions (e.g., missing pixels, lighting changes, distortions).\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ Commonly Used Transforms\n",
        "\n",
        "### 1. **Horizontal Flip**\n",
        "\n",
        "```python\n",
        "A.HorizontalFlip(p=0.5)\n",
        "```\n",
        "\n",
        "* Randomly flips the image left-to-right.\n",
        "* Helps in tasks where orientation does not matter (e.g., classification, segmentation).\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **ShiftScaleRotate**\n",
        "\n",
        "```python\n",
        "A.ShiftScaleRotate(\n",
        "    shift_limit=0.0625,  # Max fraction for shifting image (e.g., 6.25%)\n",
        "    scale_limit=0.1,     # Zoom in/out up to Â±10%\n",
        "    rotate_limit=45,     # Rotate within Â±45 degrees\n",
        "    p=0.5\n",
        ")\n",
        "```\n",
        "\n",
        "* Applies random **translation (shift)**, **zoom (scale)**, and **rotation**.\n",
        "* Useful in making models invariant to small positional changes.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **CoarseDropout**\n",
        "\n",
        "```python\n",
        "A.CoarseDropout(\n",
        "    max_holes=1,       # max number of dropped regions\n",
        "    max_height=16,     # max height of dropped block\n",
        "    max_width=16,      # max width of dropped block\n",
        "    min_holes=1,       # min number of dropped regions\n",
        "    min_height=16,     # min height of dropped block\n",
        "    min_width=16,      # min width of dropped block\n",
        "    fill_value=(123.68, 116.78, 103.94),  # dataset mean\n",
        "    mask_fill_value=None,\n",
        "    p=0.5\n",
        ")\n",
        "```\n",
        "\n",
        "* Randomly \"drops out\" square/rectangular regions from the image.\n",
        "* Similar to **Cutout regularization**.\n",
        "* Forces the model to rely on surrounding context instead of only specific pixels.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ Example Pipeline\n",
        "\n",
        "```python\n",
        "import albumentations as A\n",
        "\n",
        "mean = (123.68, 116.78, 103.94)  # dataset mean (replace with yours)\n",
        "\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.5),\n",
        "    A.CoarseDropout(\n",
        "        max_holes=1, max_height=16, max_width=16,\n",
        "        min_holes=1, min_height=16, min_width=16,\n",
        "        fill_value=mean, mask_fill_value=None, p=0.5\n",
        "    )\n",
        "])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ Tips for Use\n",
        "\n",
        "* Always calculate your **dataset mean and std** before setting `fill_value`.\n",
        "* Use different `p` values to control augmentation probability.\n",
        "* When working with segmentation, remember to also pass `mask` alongside `image` in `transform(image=image, mask=mask)`.\n",
        "* Apply augmentations **only on training data**, not validation/test.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ Resources\n",
        "\n",
        "* [Albumentations Docs](https://albumentations.ai/docs/)\n",
        "* [Albumentations GitHub](https://github.com/albumentations-team/albumentations)\n",
        "* Research paper: *Albumentations: Fast and Flexible Image Augmentations* (Buslaev et al., 2020)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "4FTb03p0fFLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "dropout_value = 0.0001\n",
        "class ciferNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ciferNet, self).__init__()\n",
        "\n",
        "        # Conv Block 1\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), stride=2, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(dropout_value),\n",
        "        )\n",
        "\n",
        "        # Conv Block 2\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=2, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value),\n",
        "        )\n",
        "\n",
        "        # Conv Block 3\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(dropout_value),\n",
        "        )\n",
        "\n",
        "        # Conv Block 4 â†’ Depthwise separable convolution\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding=1, groups=128, bias=False),  # Depthwise conv\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(1, 1), bias=False),  # Pointwise conv\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Dropout(dropout_value),\n",
        "        )\n",
        "\n",
        "        # GAP and classifier\n",
        "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Conv2d(in_channels=256, out_channels=10, kernel_size=(1, 1), bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.classifier(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return F.log_softmax(x, dim=-1)\n"
      ],
      "metadata": {
        "id": "Sz69nwr8tH1E"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = ciferNet().to(device)\n",
        "summary(model, input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl2VtBeALu2W",
        "outputId": "a866ef19-d81b-48d3-803c-32efba75f156"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             432\n",
            "              ReLU-2           [-1, 16, 32, 32]               0\n",
            "       BatchNorm2d-3           [-1, 16, 32, 32]              32\n",
            "            Conv2d-4           [-1, 32, 16, 16]           4,608\n",
            "              ReLU-5           [-1, 32, 16, 16]               0\n",
            "       BatchNorm2d-6           [-1, 32, 16, 16]              64\n",
            "           Dropout-7           [-1, 32, 16, 16]               0\n",
            "            Conv2d-8           [-1, 64, 16, 16]          18,432\n",
            "              ReLU-9           [-1, 64, 16, 16]               0\n",
            "      BatchNorm2d-10           [-1, 64, 16, 16]             128\n",
            "           Conv2d-11             [-1, 64, 8, 8]          36,864\n",
            "             ReLU-12             [-1, 64, 8, 8]               0\n",
            "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
            "          Dropout-14             [-1, 64, 8, 8]               0\n",
            "           Conv2d-15            [-1, 128, 8, 8]          73,728\n",
            "             ReLU-16            [-1, 128, 8, 8]               0\n",
            "      BatchNorm2d-17            [-1, 128, 8, 8]             256\n",
            "          Dropout-18            [-1, 128, 8, 8]               0\n",
            "           Conv2d-19            [-1, 128, 8, 8]           1,152\n",
            "             ReLU-20            [-1, 128, 8, 8]               0\n",
            "      BatchNorm2d-21            [-1, 128, 8, 8]             256\n",
            "           Conv2d-22            [-1, 256, 8, 8]          32,768\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
            "          Dropout-25            [-1, 256, 8, 8]               0\n",
            "AdaptiveAvgPool2d-26            [-1, 256, 1, 1]               0\n",
            "           Conv2d-27             [-1, 10, 1, 1]           2,560\n",
            "================================================================\n",
            "Total params: 171,920\n",
            "Trainable params: 171,920\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.06\n",
            "Params size (MB): 0.66\n",
            "Estimated Total Size (MB): 2.73\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# Train Phase\n",
        "train_transforms = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.0625,\n",
        "        scale_limit=0.1,\n",
        "        rotate_limit=45,\n",
        "        p=0.5\n",
        "    ),\n",
        "    A.CoarseDropout(\n",
        "        max_holes=1,\n",
        "        max_height=16,\n",
        "        max_width=16,\n",
        "        min_holes=1,\n",
        "        min_height=16,\n",
        "        min_width=16,\n",
        "        fill_value=(123.68, 116.78, 103.94),\n",
        "        mask_fill_value=None,\n",
        "        p=0.5\n",
        "    ),\n",
        "    A.Normalize(mean=(0.4741, 0.4727, 0.4733),\n",
        "                std=(0.2521, 0.2520, 0.2506)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Test Phase\n",
        "test_transforms = A.Compose([\n",
        "    A.Normalize(mean=(0.4741, 0.4727, 0.4733),\n",
        "                std=(0.2521, 0.2520, 0.2506)),\n",
        "    ToTensorV2()\n",
        "])\n"
      ],
      "metadata": {
        "id": "Xo-t0YLCMA9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d34ec51-4423-4c8f-d303-50be422f1a27"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-306781532.py:13: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, min_height, min_width, fill_value, mask_fill_value' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f9bc9ae"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CIFAR10Albumentations(Dataset):\n",
        "    def __init__(self, root, train=True, download=False, transform=None):\n",
        "        self.cifar10 = datasets.CIFAR10(root=root, train=train, download=download)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.cifar10[index]\n",
        "        if self.transform:\n",
        "            # Albumentations requires the image to be passed as a keyword argument 'image'\n",
        "            image = self.transform(image=np.array(image))['image'] # Convert PIL to numpy array before applying transform\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cifar10)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "train = CIFAR10Albumentations('./data', train=True, download=True, transform=train_transforms)\n",
        "test = CIFAR10Albumentations('./data', train=False, download=True, transform=test_transforms)"
      ],
      "metadata": {
        "id": "YhgskLdmOZFo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "train_dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "test_dataloader_args = dict(shuffle=False, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=False, batch_size=64)\n",
        "\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **train_dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **test_dataloader_args)"
      ],
      "metadata": {
        "id": "YqXdGOhTOyrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "320145cc-d238-405a-ba2a-9688d004d831"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss.item()) # Added .item()\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "\n",
        "    pred = y_pred.float().argmax(dim=1, keepdim=True)  # get the index of the max log-probability, convert to float\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.float().argmax(dim=1, keepdim=True)  # get the index of the max log-probability, convert to float\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss) # Added .item()\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))"
      ],
      "metadata": {
        "id": "LT_W_lCuPb_b"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "model =  ciferNet().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "# scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "\n",
        "\n",
        "EPOCHS = 35\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    # scheduler.step()\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "id": "iEB6WDqsPdHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7143aab2-d9e2-48d8-c66d-9ca467d4cd7a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.531897783279419 Batch_id=390 Accuracy=40.73: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 17.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4204, Accuracy: 5055/10000 (50.55%)\n",
            "\n",
            "EPOCH: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.1379144191741943 Batch_id=390 Accuracy=53.45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:22<00:00, 17.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.1288, Accuracy: 5845/10000 (58.45%)\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.0048496723175049 Batch_id=390 Accuracy=59.30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 18.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.9795, Accuracy: 6514/10000 (65.14%)\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9151809811592102 Batch_id=390 Accuracy=63.10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:20<00:00, 18.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.9292, Accuracy: 6715/10000 (67.15%)\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9750941395759583 Batch_id=390 Accuracy=66.13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:22<00:00, 17.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8151, Accuracy: 7133/10000 (71.33%)\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.8609898686408997 Batch_id=390 Accuracy=68.55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 17.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7486, Accuracy: 7370/10000 (73.70%)\n",
            "\n",
            "EPOCH: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6417814493179321 Batch_id=390 Accuracy=70.50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 17.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7025, Accuracy: 7516/10000 (75.16%)\n",
            "\n",
            "EPOCH: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.8449007868766785 Batch_id=390 Accuracy=71.93: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:20<00:00, 19.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6936, Accuracy: 7605/10000 (76.05%)\n",
            "\n",
            "EPOCH: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7757751941680908 Batch_id=390 Accuracy=73.24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 18.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6451, Accuracy: 7747/10000 (77.47%)\n",
            "\n",
            "EPOCH: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6164972186088562 Batch_id=390 Accuracy=74.05: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:22<00:00, 17.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6112, Accuracy: 7871/10000 (78.71%)\n",
            "\n",
            "EPOCH: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9166147112846375 Batch_id=390 Accuracy=75.13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 17.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6139, Accuracy: 7860/10000 (78.60%)\n",
            "\n",
            "EPOCH: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.609209418296814 Batch_id=390 Accuracy=75.77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:20<00:00, 18.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5872, Accuracy: 8011/10000 (80.11%)\n",
            "\n",
            "EPOCH: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.620639979839325 Batch_id=390 Accuracy=76.49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 18.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5800, Accuracy: 7983/10000 (79.83%)\n",
            "\n",
            "EPOCH: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5686163902282715 Batch_id=390 Accuracy=77.23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:22<00:00, 17.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5667, Accuracy: 8085/10000 (80.85%)\n",
            "\n",
            "EPOCH: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7344892024993896 Batch_id=390 Accuracy=77.86: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:22<00:00, 17.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5647, Accuracy: 8077/10000 (80.77%)\n",
            "\n",
            "EPOCH: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4998207092285156 Batch_id=390 Accuracy=78.47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 18.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5588, Accuracy: 8067/10000 (80.67%)\n",
            "\n",
            "EPOCH: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5728510618209839 Batch_id=390 Accuracy=78.85: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:20<00:00, 18.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5338, Accuracy: 8171/10000 (81.71%)\n",
            "\n",
            "EPOCH: 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.711301326751709 Batch_id=390 Accuracy=79.22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 17.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5422, Accuracy: 8150/10000 (81.50%)\n",
            "\n",
            "EPOCH: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7555129528045654 Batch_id=390 Accuracy=79.77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 17.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5241, Accuracy: 8229/10000 (82.29%)\n",
            "\n",
            "EPOCH: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5390901565551758 Batch_id=390 Accuracy=80.16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 18.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5124, Accuracy: 8223/10000 (82.23%)\n",
            "\n",
            "EPOCH: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.676734983921051 Batch_id=390 Accuracy=80.45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 18.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5078, Accuracy: 8228/10000 (82.28%)\n",
            "\n",
            "EPOCH: 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.42247533798217773 Batch_id=390 Accuracy=80.85: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 17.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5203, Accuracy: 8188/10000 (81.88%)\n",
            "\n",
            "EPOCH: 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.40805310010910034 Batch_id=390 Accuracy=80.89: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 17.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5026, Accuracy: 8258/10000 (82.58%)\n",
            "\n",
            "EPOCH: 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.8127546310424805 Batch_id=390 Accuracy=81.38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:22<00:00, 17.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4964, Accuracy: 8290/10000 (82.90%)\n",
            "\n",
            "EPOCH: 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5304981470108032 Batch_id=390 Accuracy=81.92: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 18.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4981, Accuracy: 8265/10000 (82.65%)\n",
            "\n",
            "EPOCH: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6029830574989319 Batch_id=390 Accuracy=82.03: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:20<00:00, 18.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4973, Accuracy: 8310/10000 (83.10%)\n",
            "\n",
            "EPOCH: 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5481793284416199 Batch_id=390 Accuracy=82.34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 18.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4881, Accuracy: 8348/10000 (83.48%)\n",
            "\n",
            "EPOCH: 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6109610199928284 Batch_id=390 Accuracy=82.37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 17.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4775, Accuracy: 8387/10000 (83.87%)\n",
            "\n",
            "EPOCH: 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4804688096046448 Batch_id=390 Accuracy=82.55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 17.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4822, Accuracy: 8369/10000 (83.69%)\n",
            "\n",
            "EPOCH: 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.3598008453845978 Batch_id=390 Accuracy=82.71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:20<00:00, 18.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4872, Accuracy: 8357/10000 (83.57%)\n",
            "\n",
            "EPOCH: 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7523231506347656 Batch_id=390 Accuracy=83.17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 18.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4777, Accuracy: 8390/10000 (83.90%)\n",
            "\n",
            "EPOCH: 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.47311505675315857 Batch_id=390 Accuracy=83.00: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 17.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4807, Accuracy: 8374/10000 (83.74%)\n",
            "\n",
            "EPOCH: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.49544039368629456 Batch_id=390 Accuracy=83.55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 17.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4671, Accuracy: 8444/10000 (84.44%)\n",
            "\n",
            "EPOCH: 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.48013001680374146 Batch_id=390 Accuracy=83.73: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:20<00:00, 18.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4654, Accuracy: 8448/10000 (84.48%)\n",
            "\n",
            "EPOCH: 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4376187324523926 Batch_id=390 Accuracy=83.77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:21<00:00, 18.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4711, Accuracy: 8382/10000 (83.82%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KbK60O1UPfvy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}