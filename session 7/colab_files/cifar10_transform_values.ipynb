{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEdRTZiVFJ2a",
        "outputId": "de5c6f1e-1a35-4e65-8527-573d476af22b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Load the dataset without normalization**\n",
        "\n",
        "First, load the CIFAR-10 training dataset. To calculate the original mean and standard deviation, you must use a minimal transform that only converts the images to tensors"
      ],
      "metadata": {
        "id": "4zP08BiQGaJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train = True, download= True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SI1CnO9FemL",
        "outputId": "de6dcd3d-9e5c-4f07-d9df-87193bafd93e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:06<00:00, 27.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Stack all images into a single tensor**\n",
        "\n",
        "Next, iterate through the training dataset and combine all the image tensors into one large tensor. This will create a tensor of shape [N, C, H, W], where N is the number of images, C is the number of channels, and H and W are the height and width"
      ],
      "metadata": {
        "id": "taSzxkn2GjXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_images =[]\n",
        "for images, _ in trainset:\n",
        "  all_images.append(images)\n",
        "all_images_tensor = torch.stack(all_images)\n",
        "\n",
        "print(f\"Shape of the stacked images tensor: {all_images_tensor.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwkHB4QiGlPe",
        "outputId": "e7d41bed-577e-4d81-ea25-32e0260ea8fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the stacked images tensor: torch.Size([50000, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_images[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4GSDlEwG3OB",
        "outputId": "12321389-1336-42ad-ddf2-abb117f0a9a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2078, 0.2118, 0.2196,  ..., 0.1843, 0.1608, 0.0941],\n",
              "         [0.1804, 0.2078, 0.2118,  ..., 0.1647, 0.1529, 0.1098],\n",
              "         [0.1765, 0.1961, 0.1804,  ..., 0.1490, 0.1412, 0.1137],\n",
              "         ...,\n",
              "         [0.2784, 0.2902, 0.3137,  ..., 0.2000, 0.1804, 0.1922],\n",
              "         [0.2941, 0.3098, 0.3176,  ..., 0.2392, 0.2510, 0.1882],\n",
              "         [0.3333, 0.3333, 0.3373,  ..., 0.2392, 0.2510, 0.1922]],\n",
              "\n",
              "        [[0.2549, 0.2471, 0.2353,  ..., 0.2000, 0.1765, 0.1098],\n",
              "         [0.2314, 0.2431, 0.2314,  ..., 0.1804, 0.1686, 0.1255],\n",
              "         [0.2314, 0.2353, 0.2039,  ..., 0.1647, 0.1569, 0.1294],\n",
              "         ...,\n",
              "         [0.3255, 0.3255, 0.3333,  ..., 0.2118, 0.1922, 0.1961],\n",
              "         [0.3216, 0.3333, 0.3333,  ..., 0.2549, 0.2627, 0.1961],\n",
              "         [0.3255, 0.3294, 0.3373,  ..., 0.2549, 0.2627, 0.1961]],\n",
              "\n",
              "        [[0.2078, 0.2039, 0.1961,  ..., 0.1961, 0.1725, 0.1059],\n",
              "         [0.1608, 0.1765, 0.1725,  ..., 0.1765, 0.1647, 0.1216],\n",
              "         [0.1490, 0.1608, 0.1333,  ..., 0.1608, 0.1529, 0.1255],\n",
              "         ...,\n",
              "         [0.2588, 0.2588, 0.2627,  ..., 0.1294, 0.1333, 0.1608],\n",
              "         [0.2627, 0.2706, 0.2627,  ..., 0.1608, 0.1882, 0.1608],\n",
              "         [0.2784, 0.2784, 0.2745,  ..., 0.1529, 0.1804, 0.1608]]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_images_tensor[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxJW5QdIG_At",
        "outputId": "8cec6b31-798e-4eb7-fd38-8c6f243ec28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2314, 0.1686, 0.1961,  ..., 0.6196, 0.5961, 0.5804],\n",
              "         [0.0627, 0.0000, 0.0706,  ..., 0.4824, 0.4667, 0.4784],\n",
              "         [0.0980, 0.0627, 0.1922,  ..., 0.4627, 0.4706, 0.4275],\n",
              "         ...,\n",
              "         [0.8157, 0.7882, 0.7765,  ..., 0.6275, 0.2196, 0.2078],\n",
              "         [0.7059, 0.6784, 0.7294,  ..., 0.7216, 0.3804, 0.3255],\n",
              "         [0.6941, 0.6588, 0.7020,  ..., 0.8471, 0.5922, 0.4824]],\n",
              "\n",
              "        [[0.2431, 0.1804, 0.1882,  ..., 0.5176, 0.4902, 0.4863],\n",
              "         [0.0784, 0.0000, 0.0314,  ..., 0.3451, 0.3255, 0.3412],\n",
              "         [0.0941, 0.0275, 0.1059,  ..., 0.3294, 0.3294, 0.2863],\n",
              "         ...,\n",
              "         [0.6667, 0.6000, 0.6314,  ..., 0.5216, 0.1216, 0.1333],\n",
              "         [0.5451, 0.4824, 0.5647,  ..., 0.5804, 0.2431, 0.2078],\n",
              "         [0.5647, 0.5059, 0.5569,  ..., 0.7216, 0.4627, 0.3608]],\n",
              "\n",
              "        [[0.2471, 0.1765, 0.1686,  ..., 0.4235, 0.4000, 0.4039],\n",
              "         [0.0784, 0.0000, 0.0000,  ..., 0.2157, 0.1961, 0.2235],\n",
              "         [0.0824, 0.0000, 0.0314,  ..., 0.1961, 0.1961, 0.1647],\n",
              "         ...,\n",
              "         [0.3765, 0.1333, 0.1020,  ..., 0.2745, 0.0275, 0.0784],\n",
              "         [0.3765, 0.1647, 0.1176,  ..., 0.3686, 0.1333, 0.1333],\n",
              "         [0.4549, 0.3686, 0.3412,  ..., 0.5490, 0.3294, 0.2824]]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Reshape and compute the channel-wise mean**\n",
        "\n",
        "To calculate the mean for each channel, you need to reshape the tensor so that all pixel values for each channel are in a single dimension. This can be done with all_images_tensor.view(3, -1), which produces a tensor of shape [3, 51200000] (3 channels, and 50,000 * 32 * 32 pixels per channel). Then, take the mean along the pixel dimension (dim=1)."
      ],
      "metadata": {
        "id": "FjL5UOHkHTy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the tensor to group all pixel values for each channel\n",
        "channel_wise_pixels = all_images_tensor.view(3,-1)\n",
        "\n",
        "# Calculate the mean for each channel\n",
        "mean = channel_wise_pixels.mean(dim=1)\n",
        "\n",
        "print(f\"Mean for each channel: {mean}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfwilJM9HLXL",
        "outputId": "3655d665-769a-4ead-dd8b-82865700fdaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean for each channel: tensor([0.4741, 0.4727, 0.4733])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Reshape and compute the channel-wise standard deviation**\n",
        "\n",
        "The same process is used for the standard deviation. After reshaping, calculate the standard deviation along the pixel dimension."
      ],
      "metadata": {
        "id": "yMj3w-Y6Hriz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "channel_wise_pixels = all_images_tensor.view(3,-1)\n",
        "std = channel_wise_pixels.std(dim=1)\n",
        "print(f\"Standard deviation for each channel: {std}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9reX-dfsHnuS",
        "outputId": "2ede6cc4-c9b4-4734-9575-10759f673106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard deviation for each channel: tensor([0.2521, 0.2520, 0.2506])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hG2ynplhHyi3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}